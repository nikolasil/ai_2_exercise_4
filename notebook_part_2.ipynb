{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"colab":{"name":"4_2 LAST VERSION.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["# Nikolas Iliopoulos 1115201800332\n","# AI_2 Part 2"],"metadata":{"id":"Fx7PFYEh73Ts"}},{"cell_type":"markdown","source":["# Install Tranfsormers"],"metadata":{"id":"b0QLj8p0kT-q"}},{"cell_type":"code","source":["!pip install transformers\n","!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json -O train-v2.0.json\n","!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json -O dev-v2.0.json\n","from transformers import AutoTokenizer\n","from transformers import DistilBertForQuestionAnswering\n","\n","import torch\n","from torch.utils.data import TensorDataset\n","from torch.optim import AdamW\n","\n","import numpy as np\n","import pandas as pd\n","\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import roc_curve,roc_auc_score, auc"],"metadata":{"id":"8CvRyeviIN1c","execution":{"iopub.status.busy":"2022-03-13T15:02:30.147334Z","iopub.execute_input":"2022-03-13T15:02:30.14788Z","iopub.status.idle":"2022-03-13T15:02:46.880143Z","shell.execute_reply.started":"2022-03-13T15:02:30.147664Z","shell.execute_reply":"2022-03-13T15:02:46.879119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Functions for computing F1"],"metadata":{"id":"gbmkYSDFmCug"}},{"cell_type":"code","source":["def compute_f1(prediction, truth):\n","    pred_tokens = normalize_text(prediction).split()\n","    truth_tokens = normalize_text(truth).split()\n","\n","    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n","    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n","        return int(pred_tokens == truth_tokens)\n","\n","    common_tokens = set(pred_tokens) & set(truth_tokens)\n","\n","    # if there are no common tokens then f1 = 0\n","    if len(common_tokens) == 0:\n","        return 0\n","\n","    prec = len(common_tokens) / len(pred_tokens)\n","    rec = len(common_tokens) / len(truth_tokens)\n","\n","    return 2 * (prec * rec) / (prec + rec)\n","\n","def normalize_text(s):\n","    import string, re\n","\n","    def remove_articles(text):\n","        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n","        return re.sub(regex, \" \", text)\n","\n","    def white_space_fix(text):\n","        return \" \".join(text.split())\n","\n","    def remove_punc(text):\n","        exclude = set(string.punctuation)\n","        return \"\".join(ch for ch in text if ch not in exclude)\n","\n","    def lower(text):\n","        return text.lower()\n","\n","    return white_space_fix(remove_articles(remove_punc(lower(s))))"],"metadata":{"execution":{"iopub.status.busy":"2022-03-13T15:02:46.882445Z","iopub.execute_input":"2022-03-13T15:02:46.882816Z","iopub.status.idle":"2022-03-13T15:02:46.89476Z","shell.execute_reply.started":"2022-03-13T15:02:46.882761Z","shell.execute_reply":"2022-03-13T15:02:46.89372Z"},"trusted":true,"id":"LH73jrls67-S"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Define Trainer"],"metadata":{"id":"RhoCPUAQ7OGR"}},{"cell_type":"code","source":["# reading the training json\n","data = pd.read_json('./train-v2.0.json')\n","# reading the validation json\n","data_Val = pd.read_json('./dev-v2.0.json')\n","\n","class MyDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, answers):\n","        self.encodings = encodings\n","        self.answers = answers\n","        \n","    def __getitem__(self, index):\n","        item = {}\n","        for key, val in self.encodings.items():\n","            item[key] = torch.tensor(val[index])\n","        item['answer'] = self.answers[index]\n","        return item\n","\n","    def __len__(self):\n","        return len(self.answers)\n","\n","class MyTrainer():\n","    def __init__(self, lr, epochs, batchSize):\n","        print(\"__init__()\")\n","        self.lr = lr\n","        self.epochs = epochs\n","        self.batchSize = batchSize\n","        self.maxLength = 512\n","        self.model = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-uncased')\n","        self.tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n","        self.optimizer = AdamW(self.model.parameters(),\n","                        lr=self.lr,\n","                        eps=1e-8)\n","        self.use_cuda = torch.cuda.is_available()\n","        self.device = torch.device(\"cuda\" if self.use_cuda else \"cpu\")\n","        print(\"maxLength=\",self.maxLength)\n","        print(\"Device=\",self.device)\n","        if self.use_cuda:\n","            # LOAD THE MODEL TO THE GPU\n","            self.model = self.model.cuda()\n","            print('GPU Model', torch.cuda.get_device_name(0))\n","\n","    def processData(self, data):\n","        print(\"processData()\")\n","        self.texts, self.queries, self.answers = [], [], []\n","\n","        for d in data['data']:\n","            for paragraph in d['paragraphs']:\n","                context = paragraph['context']\n","                for qas in paragraph['qas']:\n","                    question = qas['question']\n","                    for answer in qas['answers']:\n","                        self.texts.append(context)\n","                        self.queries.append(question)\n","                        self.answers.append(answer)\n","\n","        for answer, text in zip(self.answers,self.texts):\n","            indexStart = answer['answer_start']\n","            indexEnd = indexStart + len(answer['text'])\n","            \n","            if text[indexStart:indexEnd] == answer['text']:\n","                answer['answer_end']   = indexEnd\n","            elif text[ indexStart-1 : indexEnd-1 ] == answer['text']:\n","                answer['answer_start'] = indexStart - 1\n","                answer['answer_end']   = indexEnd   - 1  \n","            elif text[ indexStart-2 : indexEnd-2 ] == answer['text']:\n","                answer['answer_start'] = indexStart - 2\n","                answer['answer_end']   = indexEnd   - 2  \n","        \n","    def prepareInputs(self):\n","        print(\"prepareInputs()\")\n","\n","        out = self.tokenizer(self.texts,\n","                                self.queries,\n","                                truncation=True,\n","                                padding=True)\n","                                \n","        startIndex, endIndex = [], []\n","\n","        count = 0\n","\n","        for i in range(len(self.answers)):\n","          startIndex.append(out.char_to_token(i, self.answers[i]['answer_start']))\n","          endIndex.append(out.char_to_token(i, self.answers[i]['answer_end']))\n","\n","          # if start position is None, the answer passage has been truncated\n","          if startIndex[-1] is None:\n","            startIndex[-1] = self.tokenizer.model_max_length\n","            \n","          # if end position is None, the 'char_to_token' function points to the space after the correct token, so add - 1\n","          if endIndex[-1] is None:\n","            endIndex[-1] = out.char_to_token(i, self.answers[i]['answer_end'] - 1)\n","            # if end position is still None the answer passage has been truncated\n","            if endIndex[-1] is None:\n","              count += 1\n","              endIndex[-1] = self.tokenizer.model_max_length\n","\n","        # Update the data in dictionary\n","        out.update({'startIndex': startIndex, 'endIndex': endIndex})\n","\n","        self.dataloader_train = torch.utils.data.DataLoader(MyDataset(out,self.answers), batch_size=self.batchSize, shuffle=True)\n","    def train(self):\n","         totalSteps = len(self.dataloader_train)\n","         n_epoch=0\n","         self.iters = []\n","         self.losses = []\n","\n","         self.model.train()\n","         for epoch in range(self.epochs):\n","            batch_losses = []\n","\n","            # TRAINING\n","            for batch in tqdm(self.dataloader_train):\n","                # LOAD THE DATA TO THE GPU\n","                input_ids = batch['input_ids'].to(self.device)\n","                attention_mask = batch['attention_mask'].to(self.device)\n","                startIndex  = batch['startIndex'].to(self.device)\n","                endIndex   = batch['endIndex'].to(self.device)\n","                answer = batch['answer']['text']\n","      \n","                self.model.zero_grad()\n","\n","                outputs = self.model(input_ids, attention_mask=attention_mask, start_positions=startIndex,end_positions=endIndex)\n","                loss = outputs.loss\n","                \n","                # store the loss of that batch\n","                batch_losses.append(loss.item())\n","                # BackwardPropagation to calculate the gradients.\n","                loss.backward()\n","                # Clip Gradients\n","                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n","                # Update parameters\n","                self.optimizer.step()\n","\n","                n_epoch+=1\n","\n","            self.losses.append(sum(batch_losses)/len(self.dataloader_train))\n","            self.iters.append(n_epoch)\n","\n","            print(\"Loss:    \", sum(batch_losses)/len(self.dataloader_train))\n","    def validate(self,data_Val):\n","        self.model.eval()\n","        self.f1_Val = []\n","        self.val_iters = 0\n","        for group in tqdm(data_Val['data']):\n","            for passage in group['paragraphs']:\n","                context = passage['context']\n","                for qa in passage['qas']:\n","                    question = qa['question']\n","                    for answer in qa['answers']:\n","#                         text - > context\n","                        tokens = self.tokenizer.encode_plus(context, question, truncation=True, return_tensors = 'pt')\n","                        tokens.to(self.device)\n","                        outputs = self.model(**tokens)\n","                        startIndex_pred = torch.argmax(outputs.start_logits)\n","                        endIndex_pred = torch.argmax(outputs.end_logits) + 1\n","                        answer_pred = self.tokenizer.convert_tokens_to_string(self.tokenizer.convert_ids_to_tokens(tokens['input_ids'][0][startIndex_pred:endIndex_pred]))\n","                        f1 = compute_f1(answer_pred,answer['text'])\n","                        self.f1_Val.append(f1)\n","                        self.val_iters += 1\n","                        \n","                        \n","    def plot(self):\n","        plt.title(\"Learning Curve\")\n","        plt.plot(self.iters, self.losses, label=\"Train Loss\")\n","        plt.xlabel(\"Iteration(Epoch)\")\n","        plt.ylabel(\"Loss\")\n","        plt.legend(loc='best')\n","        plt.show()\n","        print('F1 ',sum(self.f1_Val)/self.val_iters)\n"],"metadata":{"id":"RY1hMBa_l5h8","execution":{"iopub.status.busy":"2022-03-13T15:02:46.898764Z","iopub.execute_input":"2022-03-13T15:02:46.899226Z","iopub.status.idle":"2022-03-13T15:02:48.492552Z","shell.execute_reply.started":"2022-03-13T15:02:46.89918Z","shell.execute_reply":"2022-03-13T15:02:48.4915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Train & Plot"],"metadata":{"id":"C8L7LFX57Sec"}},{"cell_type":"code","source":["trainer = MyTrainer(2e-5, 2, 16)\n","trainer.processData(data)\n","trainer.prepareInputs()\n","trainer.train()\n","trainer.validate(data_Val)\n","trainer.plot()"],"metadata":{"id":"J54qOkTLh4kY","execution":{"iopub.status.busy":"2022-03-13T15:02:48.495134Z","iopub.execute_input":"2022-03-13T15:02:48.495444Z","iopub.status.idle":"2022-03-13T15:03:11.426667Z","shell.execute_reply.started":"2022-03-13T15:02:48.495403Z","shell.execute_reply":"2022-03-13T15:03:11.42556Z"},"trusted":true},"execution_count":null,"outputs":[]}]}